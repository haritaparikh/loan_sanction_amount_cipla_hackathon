{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "import os\n",
    "import pickle \n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_key = \"Customer ID\"\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "data_path = \"../data\"\n",
    "processed_data_path = os.path.join(data_path, \"processed_data\")\n",
    "output_path = os.path.join(\"../output\")\n",
    "model_path = os.path.join(output_path, \"model\", \"artifact\")\n",
    "metrics_path = os.path.join(output_path, \"model\", \"metrics\")\n",
    "predict_path = os.path.join(output_path, \"predictions\")\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)  \n",
    "if not os.path.exists(predict_path):\n",
    "    os.makedirs(predict_path)  \n",
    "if not os.path.exists(metrics_path):\n",
    "    os.makedirs(metrics_path) \n",
    "    \n",
    "def save_pickle_model(model_parameters, \n",
    "                      model_path, \n",
    "                      file_opts):\n",
    "    # Save the model to disk\n",
    "    with open(model_path, \n",
    "              file_opts) as pickle_out:\n",
    "        pickle.dump(model_parameters, \n",
    "                    pickle_out)\n",
    "\n",
    "def load_pickle_model(model_path, \n",
    "                      file_opts):\n",
    "    # Load the model from disk\n",
    "    with open(model_path, \n",
    "              file_opts) as pickle_in:\n",
    "        return pickle.load(pickle_in)\n",
    "    \n",
    "def save_dict_to_json(dictionary, path, file_opts):\n",
    "    # save model metrics\n",
    "    with open(path, file_opts) as outfile:\n",
    "        json.dump(dictionary, outfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                   \"x_train.csv\"))\n",
    "x_val = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                 \"x_val.csv\"))\n",
    "y_train = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                   \"y_train.csv\"))\n",
    "y_val = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                 \"y_val.csv\"))\n",
    "x_test = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                  \"x_test.csv\"))\n",
    "del x_train[primary_key]\n",
    "del x_val[primary_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 105.0min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 158.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'min_samples_leaf': [1, 10, 100],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 500, 1000]},\n",
       "             scoring='neg_mean_absolute_error', verbose=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model development\n",
    "\n",
    "params = {'n_estimators':[100, 500, 1000],\n",
    "          'min_samples_split':[2, 5, 10],\n",
    "          'min_samples_leaf':[1,10,100]}\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "rf_model = GridSearchCV(model,\n",
    "                         cv=10,\n",
    "                         param_grid=params,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=2,\n",
    "                         scoring='neg_mean_absolute_error')\n",
    "\n",
    "rf_model.fit(x_train,\n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gini-importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dependents_0</th>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type of Employment_Drivers</th>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type of Employment_Managers</th>\n",
       "      <td>0.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type of Employment_Accountants</th>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type of Employment_Core staff</th>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type of Employment_Sales staff</th>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents_4.0</th>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location_Rural</th>\n",
       "      <td>0.000358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No. of Defaults</th>\n",
       "      <td>0.000458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type of Employment_Laborers</th>\n",
       "      <td>0.000489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents_1.0</th>\n",
       "      <td>0.000523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location_Semi-Urban</th>\n",
       "      <td>0.000690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents_3.0</th>\n",
       "      <td>0.000755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type of Employment_missing_val</th>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Commercial associate</th>\n",
       "      <td>0.000788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expense Type 1_N</th>\n",
       "      <td>0.000817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Working</th>\n",
       "      <td>0.000872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents_2.0</th>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income (USD)</th>\n",
       "      <td>0.006962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property Price</th>\n",
       "      <td>0.008630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Current Loan Expenses (USD)</th>\n",
       "      <td>0.008815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property Age</th>\n",
       "      <td>0.010331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Pensioner</th>\n",
       "      <td>0.041929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Co-Applicant</th>\n",
       "      <td>0.079562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit Score</th>\n",
       "      <td>0.208544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan Amount Request (USD)</th>\n",
       "      <td>0.626434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Gini-importance\n",
       "Dependents_0                            0.000080\n",
       "Type of Employment_Drivers              0.000098\n",
       "Type of Employment_Managers             0.000103\n",
       "Type of Employment_Accountants          0.000149\n",
       "Type of Employment_Core staff           0.000192\n",
       "Type of Employment_Sales staff          0.000222\n",
       "Dependents_4.0                          0.000301\n",
       "Location_Rural                          0.000358\n",
       "No. of Defaults                         0.000458\n",
       "Type of Employment_Laborers             0.000489\n",
       "Dependents_1.0                          0.000523\n",
       "Location_Semi-Urban                     0.000690\n",
       "Dependents_3.0                          0.000755\n",
       "Type of Employment_missing_val          0.000785\n",
       "Profession_Commercial associate         0.000788\n",
       "Expense Type 1_N                        0.000817\n",
       "Profession_Working                      0.000872\n",
       "Dependents_2.0                          0.001111\n",
       "Income (USD)                            0.006962\n",
       "Property Price                          0.008630\n",
       "Current Loan Expenses (USD)             0.008815\n",
       "Property Age                            0.010331\n",
       "Profession_Pensioner                    0.041929\n",
       "Co-Applicant                            0.079562\n",
       "Credit Score                            0.208544\n",
       "Loan Amount Request (USD)               0.626434"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "feats = {} \n",
    "for feature, importance in zip(x_train.columns, rf_model.feature_importances_):\n",
    "    feats[feature] = importance \n",
    "\n",
    "# importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "importances.sort_values(by='Gini-importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict_to_json(feats, os.path.join(\n",
    "    metrics_path, 'feature_importances.json'), 'w')\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 1000}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(min_samples_leaf=10, min_samples_split=5,\n",
       "                      n_estimators=1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(rf_model.best_estimator_, os.path.join(\n",
    "    model_path, \"rf_model.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 85.4665563620116, 'val': 79.71147529172381}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "rf_train_predicted = rf_model.predict(x_train)\n",
    "rf_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                      rf_train_predicted)\n",
    "rf_val_predicted = rf_model.predict(x_val)\n",
    "rf_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                    rf_val_predicted)\n",
    "rf_metric = {}\n",
    "rf_metric[\"train\"] = rf_score_train\n",
    "rf_metric[\"val\"] = rf_score_val\n",
    "save_dict_to_json(rf_metric, os.path.join(\n",
    "    metrics_path, 'rf_metric.json'), 'w')\n",
    "rf_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_features_list = [\"Loan Amount Request (USD)\", \"Credit Score\", \"Co-Applicant\", \"Profession_Pensioner\", \"Property Age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_imp = x_train[keep_features_list]\n",
    "x_val_imp  = x_train[keep_features_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(min_samples_leaf=10, min_samples_split=5,\n",
       "                      n_estimators=1000)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model development\n",
    "\n",
    "rf_model_imp = RandomForestRegressor(min_samples_leaf= 10, min_samples_split= 5, n_estimators= 1000)\n",
    "rf_model_imp.fit(x_train,\n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(rf_model_imp, os.path.join(\n",
    "    model_path, \"rf_model_imp.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 85.47045966986609, 'val': 79.69241991509338}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "rf_imp_train_predicted = rf_model_imp.predict(x_train)\n",
    "rf_imp_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                      rf_imp_train_predicted)\n",
    "rf_imp_val_predicted = rf_model_imp.predict(x_val)\n",
    "rf_imp_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                    rf_imp_val_predicted)\n",
    "rf_imp_metric = {}\n",
    "rf_imp_metric[\"train\"] = rf_imp_score_train\n",
    "rf_imp_metric[\"val\"] = rf_imp_score_val\n",
    "save_dict_to_json(rf_imp_metric, os.path.join(\n",
    "    metrics_path, 'rf_imp_metric.json'), 'w')\n",
    "rf_imp_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoosting Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   41.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 22.0min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 40.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 64.0min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 69.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.001],\n",
       "                         'min_samples_leaf': [1, 10, 100],\n",
       "                         'min_samples_split': [5, 10],\n",
       "                         'n_estimators': [100, 500], 'tol': [0.001, 0.0001]},\n",
       "             scoring='neg_mean_absolute_error', verbose=5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model development\n",
    "\n",
    "params = {'n_estimators':[100, 500],\n",
    "        'learning_rate':[0.01, 0.001],\n",
    "        'min_samples_leaf':[1,10,100],\n",
    "        'min_samples_split': [5, 10],\n",
    "         'tol': [0.001, 0.0001]}\n",
    "\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "gb_model = GridSearchCV(model,\n",
    "                         cv=10,\n",
    "                         param_grid=params,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=5,\n",
    "                         scoring='neg_mean_absolute_error')\n",
    "gb_model.fit(x_train,\n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, min_samples_leaf=10,\n",
       "                          min_samples_split=5, n_estimators=500, tol=0.001)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(gb_model.best_estimator_, os.path.join(\n",
    "    model_path, \"gb_model.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 78.17347013415583, 'val': 78.2515115460802}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "gbm_train_predicted = gb_model.predict(x_train)\n",
    "gbm_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                       gbm_train_predicted)\n",
    "gbm_val_predicted = gb_model.predict(x_val)\n",
    "gbm_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                     gbm_val_predicted)\n",
    "\n",
    "gbm_metric = {}\n",
    "gbm_metric[\"train\"] = gbm_score_train\n",
    "gbm_metric[\"val\"] = gbm_score_val\n",
    "save_dict_to_json(gbm_metric, os.path.join(\n",
    "    metrics_path, 'gbm_metric.json'), 'w')\n",
    "gbm_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### scaling data\n",
    "\n",
    "<br> Scaling is done to Normalize data so that priority is not given to a particular feature. \n",
    "<br> Role of Scaling is mostly important in algorithms that are distance based and require Euclidean Distance. \n",
    "<br> Random Forest is a tree-based model and hence does not require feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize x data \n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "# x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:   15.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SGDRegressor(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 1e-05],\n",
       "                         'max_iter': [500, 1000, 1500], 'penalty': ['l1', 'l2'],\n",
       "                         'tol': [0.001, 0.0001]},\n",
       "             scoring='neg_mean_absolute_error', verbose=5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model development\n",
    "\n",
    "params = {'penalty':['l1','l2'],\n",
    "          'tol':[0.001, 0.0001],\n",
    "          'alpha': [0.0001, 0.00001],\n",
    "         'max_iter': [500, 1000, 1500]}\n",
    "\n",
    "model = SGDRegressor(loss='squared_loss')\n",
    "\n",
    "ln_model = GridSearchCV(model,\n",
    "                         cv=10,\n",
    "                         param_grid=params,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=5,\n",
    "                         scoring='neg_mean_absolute_error')\n",
    "ln_model.fit(x_train_scaled, \n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=1e-05, max_iter=500, penalty='l1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(ln_model.best_estimator_, os.path.join(\n",
    "    model_path, \"ln_model.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': -478464113507.5909, 'val': -480778696440.7903}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "linear_train_predicted = ln_model.predict(x_train)\n",
    "linear_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                          linear_train_predicted)\n",
    "linear_val_predicted = ln_model.predict(x_val)\n",
    "linear_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                        linear_val_predicted)\n",
    "\n",
    "linear_metric = {}\n",
    "linear_metric[\"train\"] = linear_score_train\n",
    "linear_metric[\"val\"] = linear_score_val\n",
    "save_dict_to_json(linear_metric, os.path.join(\n",
    "    metrics_path, 'linear_metric.json'), 'w')\n",
    "linear_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=BayesianRidge(), n_jobs=-1,\n",
       "             param_grid={'tol': [0.001, 0.0001]},\n",
       "             scoring='neg_mean_absolute_error', verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model development\n",
    "\n",
    "params = {'tol':[0.001, 0.0001]}\n",
    "\n",
    "model = BayesianRidge()\n",
    "\n",
    "bayesian_ridge_model = GridSearchCV(model,\n",
    "                                    cv=10,\n",
    "                                    param_grid=params,\n",
    "                                    n_jobs=-1,\n",
    "                                    verbose=1,\n",
    "                                    scoring='neg_mean_absolute_error')\n",
    "bayesian_ridge_model.fit(x_train_scaled,\n",
    "                         y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-17937.035053770243"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_ridge_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesianRidge(tol=0.0001)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_ridge_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(bayesian_ridge_model.best_estimator_, os.path.join(\n",
    "    model_path, \"bayesian_ridge_model.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': -476641246925.34735, 'val': -478941853894.1226}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "bayesian_ridge_model_train_predicted = bayesian_ridge_model.predict(x_train)\n",
    "bayesian_ridge_model_score_train = max(0, 100)*r2_score(y_train.values.ravel(),\n",
    "                                                        bayesian_ridge_model_train_predicted)\n",
    "bayesian_ridge_val_predicted = bayesian_ridge_model.predict(x_val)\n",
    "bayesian_ridge_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                                bayesian_ridge_val_predicted)\n",
    "\n",
    "bayesian_ridge_metric = {}\n",
    "bayesian_ridge_metric[\"train\"] = bayesian_ridge_model_score_train\n",
    "bayesian_ridge_metric[\"val\"] = bayesian_ridge_score_val\n",
    "save_dict_to_json(bayesian_ridge_metric, os.path.join(\n",
    "    metrics_path, 'bayesian_ridge_metric.json'), 'w')\n",
    "bayesian_ridge_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_train_predicted_df = pd.DataFrame(gbm_train_predicted, columns = [\"gbm_train_predicted\"])\n",
    "rf_train_predicted_df = pd.DataFrame(rf_train_predicted, columns = [\"rf_train_predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grm_rf_stacking_dataframe = pd.merge(gbm_train_predicted_df,  \n",
    "                                     rf_train_predicted_df, \n",
    "                                     how=\"left\",     \n",
    "                                     left_index=True,   \n",
    "                                     right_index=True)\n",
    "stacking_dataframe = pd.merge(grm_rf_stacking_dataframe,  \n",
    "                             y_train,\n",
    "                             how=\"left\",     \n",
    "                             left_index=True,   \n",
    "                             right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbm_train_predicted</th>\n",
       "      <th>rf_train_predicted</th>\n",
       "      <th>Loan Sanction Amount (USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17759.598989</td>\n",
       "      <td>12671.998824</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110886.654357</td>\n",
       "      <td>111344.440697</td>\n",
       "      <td>132201.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76471.153147</td>\n",
       "      <td>69199.566150</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159598.188635</td>\n",
       "      <td>153349.831000</td>\n",
       "      <td>180702.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20169.904298</td>\n",
       "      <td>16082.726252</td>\n",
       "      <td>16574.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21459</th>\n",
       "      <td>98759.112017</td>\n",
       "      <td>105094.890264</td>\n",
       "      <td>109830.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21460</th>\n",
       "      <td>45101.792184</td>\n",
       "      <td>44946.765169</td>\n",
       "      <td>61641.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21461</th>\n",
       "      <td>25660.246981</td>\n",
       "      <td>25535.930691</td>\n",
       "      <td>28492.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21462</th>\n",
       "      <td>30641.222172</td>\n",
       "      <td>29300.998380</td>\n",
       "      <td>35506.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21463</th>\n",
       "      <td>17584.463561</td>\n",
       "      <td>15253.818511</td>\n",
       "      <td>17558.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21464 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gbm_train_predicted  rf_train_predicted  Loan Sanction Amount (USD)\n",
       "0             17759.598989        12671.998824                        0.00\n",
       "1            110886.654357       111344.440697                   132201.10\n",
       "2             76471.153147        69199.566150                        0.00\n",
       "3            159598.188635       153349.831000                   180702.22\n",
       "4             20169.904298        16082.726252                    16574.49\n",
       "...                    ...                 ...                         ...\n",
       "21459         98759.112017       105094.890264                   109830.53\n",
       "21460         45101.792184        44946.765169                    61641.22\n",
       "21461         25660.246981        25535.930691                    28492.34\n",
       "21462         30641.222172        29300.998380                    35506.31\n",
       "21463         17584.463561        15253.818511                    17558.39\n",
       "\n",
       "[21464 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = load_pickle_model(os.path.join(\n",
    "    model_path, \"rf_model.pickle\"), \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model = rf_model.fit(x_train,\n",
    "                              y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(stacking_model, os.path.join(\n",
    "    model_path, \"stacking_model.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 85.47872234095217, 'val': 79.70085794976289}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "stacking_train_predicted = stacking_model.predict(x_train)\n",
    "stacking_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                            stacking_train_predicted)\n",
    "stacking_val_predicted = stacking_model.predict(x_val)\n",
    "stacking_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                          stacking_val_predicted)\n",
    "stacking_metric = {}\n",
    "stacking_metric[\"train\"] = stacking_score_train\n",
    "stacking_metric[\"val\"] = stacking_score_val\n",
    "save_dict_to_json(stacking_metric, os.path.join(\n",
    "    metrics_path, 'stacking_metric.json'), 'w')\n",
    "stacking_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_model = load_pickle_model(os.path.join(\n",
    "    model_path, \"ln_model.pickle\"), \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model2 = ln_model.fit(x_train,\n",
    "                              y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(stacking_model2, os.path.join(\n",
    "    model_path, \"stacking_model2.pickle\"), \"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "stacking_train_predicted = stacking_model2.predict(x_train)\n",
    "stacking_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                            stacking_train_predicted)\n",
    "stacking_val_predicted = stacking_model2.predict(x_val)\n",
    "stacking_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                          stacking_val_predicted)\n",
    "stacking_metric = {}\n",
    "stacking_metric[\"train\"] = stacking_score_train\n",
    "stacking_metric[\"val\"] = stacking_score_val\n",
    "save_dict_to_json(stacking_metric2, os.path.join(\n",
    "    metrics_path, 'stacking_metric2.json'), 'w')\n",
    "stacking_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pk_predict = x_test[primary_key]\n",
    "x_predict = x_test.drop([primary_key],1)\n",
    "\n",
    "predicted = rf_model_imp.predict(x_predict)\n",
    "predict_df = pd.DataFrame(predicted, \n",
    "                          columns = [\"Loan Sanction Amount (USD)\"])\n",
    "\n",
    "output_dataframe = pd.merge(x_pk_predict, \n",
    "                            predict_df, \n",
    "                            how=\"left\", \n",
    "                            left_index=True, \n",
    "                            right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Loan Sanction Amount (USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-26247</td>\n",
       "      <td>85209.643363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-35067</td>\n",
       "      <td>61898.173221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C-34590</td>\n",
       "      <td>2723.485216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C-16668</td>\n",
       "      <td>54318.096853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C-12196</td>\n",
       "      <td>72719.366483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer ID  Loan Sanction Amount (USD)\n",
       "0     C-26247                85209.643363\n",
       "1     C-35067                61898.173221\n",
       "2     C-34590                 2723.485216\n",
       "3     C-16668                54318.096853\n",
       "4     C-12196                72719.366483"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataframe.to_csv(os.path.join(predict_path, \n",
    "                                     \"rf_model_imp__%s.csv\"%timestr),\n",
    "                        index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "            \n",
    "rf_model = load_pickle_model(os.path.join(\n",
    "    model_path, \"rf_model.pickle\"), \"rb\")\n",
    "\n",
    "gb_model = load_pickle_model(os.path.join(\n",
    "    model_path, \"gb_model.pickle\"), \"rb\")\n",
    "\n",
    "save_pickle_model(ln_model.best_estimator_, os.path.join(\n",
    "    model_path, \"ln_model.pickle\"), \"wb\") \n",
    "\n",
    "rf_train_predicted = rf_model.predict(x_train)\n",
    "rf_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                      rf_train_predicted)\n",
    "rf_val_predicted = rf_model.predict(x_val)\n",
    "rf_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                    rf_val_predicted)\n",
    "\n",
    "gbm_train_predicted = gb_model.predict(x_train)\n",
    "gbm_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                       gbm_train_predicted)\n",
    "gbm_val_predicted = gb_model.predict(x_val)\n",
    "gbm_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                     gbm_val_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_metric = {}\n",
    "gbm_metric[\"train\"] = gbm_score_train\n",
    "gbm_metric[\"val\"] = gbm_score_val\n",
    "save_dict_to_json(gbm_metric, os.path.join(\n",
    "    metrics_path, 'gbm_metric.json'), 'w')\n",
    "gbm_metric\n",
    "\n",
    "rf_metric = {}\n",
    "rf_metric[\"train\"] = rf_score_train\n",
    "rf_metric[\"val\"] = rf_score_val\n",
    "save_dict_to_json(rf_metric, os.path.join(\n",
    "    metrics_path, 'rf_metric.json'), 'w')\n",
    "rf_metric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
