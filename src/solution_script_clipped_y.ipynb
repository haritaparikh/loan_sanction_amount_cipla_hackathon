{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "import os\n",
    "import pickle \n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_key = \"Customer ID\"\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "data_path = \"../data\"\n",
    "processed_data_path = os.path.join(data_path, \"processed_data\")\n",
    "output_path = os.path.join(\"../output\")\n",
    "model_path = os.path.join(output_path, \"model\", \"artifact\")\n",
    "metrics_path = os.path.join(output_path, \"model\", \"metrics\")\n",
    "predict_path = os.path.join(output_path, \"predictions\")\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)  \n",
    "if not os.path.exists(predict_path):\n",
    "    os.makedirs(predict_path)  \n",
    "if not os.path.exists(metrics_path):\n",
    "    os.makedirs(metrics_path) \n",
    "    \n",
    "def save_pickle_model(model_parameters, \n",
    "                      model_path, \n",
    "                      file_opts):\n",
    "    # Save the model to disk\n",
    "    with open(model_path, \n",
    "              file_opts) as pickle_out:\n",
    "        pickle.dump(model_parameters, \n",
    "                    pickle_out)\n",
    "\n",
    "def load_pickle_model(model_path, \n",
    "                      file_opts):\n",
    "    # Load the model from disk\n",
    "    with open(model_path, \n",
    "              file_opts) as pickle_in:\n",
    "        return pickle.load(pickle_in)\n",
    "    \n",
    "def save_dict_to_json(dictionary, path, file_opts):\n",
    "    # save model metrics\n",
    "    with open(path, file_opts) as outfile:\n",
    "        json.dump(dictionary, outfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                   \"x_train.csv\"))\n",
    "x_val = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                 \"x_val.csv\"))\n",
    "y_train = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                   \"y_train.csv\"))\n",
    "y_val = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                 \"y_val.csv\"))\n",
    "x_test = pd.read_csv(os.path.join(processed_data_path, \n",
    "                                  \"x_test.csv\"))\n",
    "del x_train[primary_key]\n",
    "del x_val[primary_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 61.1min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 92.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'min_samples_leaf': [1, 10, 100],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 500, 1000]},\n",
       "             scoring='neg_mean_absolute_error', verbose=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model development\n",
    "\n",
    "params = {'n_estimators':[100, 500, 1000],\n",
    "          'min_samples_split':[2, 5, 10],\n",
    "          'min_samples_leaf':[1,10,100]}\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "rf_model = GridSearchCV(model,\n",
    "                         cv=10,\n",
    "                         param_grid=params,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=2,\n",
    "                         scoring='neg_mean_absolute_error')\n",
    "\n",
    "rf_model.fit(x_train,\n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 60.8min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 91.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'min_samples_leaf': [1, 10, 100],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 500, 1000]},\n",
       "             scoring='neg_mean_absolute_error', verbose=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.fit(x_train,\n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 1000}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(min_samples_leaf=10, min_samples_split=5,\n",
       "                      n_estimators=1000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(rf_model.best_estimator_, os.path.join(\n",
    "    model_path, \"rf_model.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 99.23613729959098, 'val': 98.95729783354649}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "rf_train_predicted = rf_model.predict(x_train)\n",
    "rf_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                      rf_train_predicted)\n",
    "rf_val_predicted = rf_model.predict(x_val)\n",
    "rf_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                    rf_val_predicted)\n",
    "rf_metric = {}\n",
    "rf_metric[\"train\"] = rf_score_train\n",
    "rf_metric[\"val\"] = rf_score_val\n",
    "save_dict_to_json(rf_metric, os.path.join(\n",
    "    metrics_path, 'rf_metric.json'), 'w')\n",
    "rf_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoosting Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 27.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 43.2min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 47.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.001],\n",
       "                         'min_samples_leaf': [1, 10, 100],\n",
       "                         'min_samples_split': [5, 10],\n",
       "                         'n_estimators': [100, 500], 'tol': [0.001, 0.0001]},\n",
       "             scoring='neg_mean_absolute_error', verbose=5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model development\n",
    "\n",
    "params = {'n_estimators':[100, 500],\n",
    "        'learning_rate':[0.01, 0.001],\n",
    "        'min_samples_leaf':[1,10,100],\n",
    "        'min_samples_split': [5, 10],\n",
    "         'tol': [0.001, 0.0001]}\n",
    "\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "gb_model = GridSearchCV(model,\n",
    "                         cv=10,\n",
    "                         param_grid=params,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=5,\n",
    "                         scoring='neg_mean_absolute_error')\n",
    "gb_model.fit(x_train,\n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, min_samples_leaf=10,\n",
       "                          min_samples_split=5, n_estimators=500, tol=0.001)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(gb_model.best_estimator_, os.path.join(\n",
    "    model_path, \"gb_model.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 98.98195864725801, 'val': 98.99583106559759}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "gbm_train_predicted = gb_model.predict(x_train)\n",
    "gbm_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                       gbm_train_predicted)\n",
    "gbm_val_predicted = gb_model.predict(x_val)\n",
    "gbm_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                     gbm_val_predicted)\n",
    "\n",
    "gbm_metric = {}\n",
    "gbm_metric[\"train\"] = gbm_score_train\n",
    "gbm_metric[\"val\"] = gbm_score_val\n",
    "save_dict_to_json(gbm_metric, os.path.join(\n",
    "    metrics_path, 'gbm_metric.json'), 'w')\n",
    "gbm_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### scaling data\n",
    "\n",
    "<br> Scaling is done to Normalize data so that priority is not given to a particular feature. \n",
    "<br> Role of Scaling is mostly important in algorithms that are distance based and require Euclidean Distance. \n",
    "<br> Random Forest is a tree-based model and hence does not require feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize x data \n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "# x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:   11.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SGDRegressor(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 1e-05],\n",
       "                         'max_iter': [500, 1000, 1500], 'penalty': ['l1', 'l2'],\n",
       "                         'tol': [0.001, 0.0001]},\n",
       "             scoring='neg_mean_absolute_error', verbose=5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model development\n",
    "\n",
    "params = {'penalty':['l1','l2'],\n",
    "          'tol':[0.001, 0.0001],\n",
    "          'alpha': [0.0001, 0.00001],\n",
    "         'max_iter': [500, 1000, 1500]}\n",
    "\n",
    "model = SGDRegressor(loss='squared_loss')\n",
    "\n",
    "ln_model = GridSearchCV(model,\n",
    "                         cv=10,\n",
    "                         param_grid=params,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=5,\n",
    "                         scoring='neg_mean_absolute_error')\n",
    "ln_model.fit(x_train_scaled, \n",
    "             y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=1e-05, max_iter=500)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(ln_model.best_estimator_, os.path.join(\n",
    "    model_path, \"ln_model.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': -1009967691358.4381, 'val': -1039974674170.0958}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "linear_train_predicted = ln_model.predict(x_train)\n",
    "linear_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                          linear_train_predicted)\n",
    "linear_val_predicted = ln_model.predict(x_val)\n",
    "linear_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                        linear_val_predicted)\n",
    "\n",
    "linear_metric = {}\n",
    "linear_metric[\"train\"] = linear_score_train\n",
    "linear_metric[\"val\"] = linear_score_val\n",
    "save_dict_to_json(linear_metric, os.path.join(\n",
    "    metrics_path, 'linear_metric.json'), 'w')\n",
    "linear_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 16.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVR(), n_jobs=-1,\n",
       "             param_grid={'gamma': [0.0001, 0.01, 0.0001],\n",
       "                         'kernel': ['rbf', 'linear', 'poly', 'sigmoid']},\n",
       "             scoring='neg_mean_absolute_error', verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model development\n",
    "\n",
    "params = {'kernel':[\"rbf\", \"linear\", \"poly\", \"sigmoid\"],\n",
    "          'gamma': [1e-4,1e-2,0.0001]}\n",
    "\n",
    "model = SVR()\n",
    "\n",
    "svm_svr_model = GridSearchCV(model,\n",
    "                             cv=10,\n",
    "                            param_grid=params,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=1,\n",
    "                            scoring='neg_mean_absolute_error')\n",
    "svm_svr_model.fit(x_train_scaled, \n",
    "                  y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12876.509709732687"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_svr_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(gamma=0.0001, kernel='linear')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_svr_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(svm_svr_model.best_estimator_, os.path.join(\n",
    "    model_path, \"svm_svr_model.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': -406862972368.9935, 'val': -420750488725.3195}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "svm_svr_model_train_predicted = svm_svr_model.predict(x_train)\n",
    "svm_svr_model_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                       svm_svr_model_train_predicted)\n",
    "svm_svr_val_predicted = svm_svr_model.predict(x_val)\n",
    "svm_svr_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                     svm_svr_val_predicted)\n",
    "\n",
    "svm_svr_metric = {}\n",
    "svm_svr_metric[\"train\"] = svm_svr_model_score_train\n",
    "svm_svr_metric[\"val\"] = svm_svr_score_val\n",
    "save_dict_to_json(svm_svr_metric, os.path.join(\n",
    "    metrics_path, 'svm_svr_metric.json'), 'w')\n",
    "svm_svr_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   10.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=BayesianRidge(), n_jobs=-1,\n",
       "             param_grid={'tol': [0.001, 0.0001]},\n",
       "             scoring='neg_mean_absolute_error', verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model development\n",
    "\n",
    "params = {'tol':[0.001, 0.0001]}\n",
    "\n",
    "model = BayesianRidge()\n",
    "\n",
    "bayesian_ridge_model = GridSearchCV(model,\n",
    "                                    cv=10,\n",
    "                                    param_grid=params,\n",
    "                                    n_jobs=-1,\n",
    "                                    verbose=1,\n",
    "                                    scoring='neg_mean_absolute_error')\n",
    "bayesian_ridge_model.fit(x_train_scaled,\n",
    "                         y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3383.3782974799046"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_ridge_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesianRidge()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_ridge_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(bayesian_ridge_model.best_estimator_, os.path.join(\n",
    "    model_path, \"bayesian_ridge_model.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': -1010137017869.9077, 'val': -1040150035264.8959}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "bayesian_ridge_model_train_predicted = bayesian_ridge_model.predict(x_train)\n",
    "bayesian_ridge_model_score_train = max(0, 100)*r2_score(y_train.values.ravel(),\n",
    "                                                        bayesian_ridge_model_train_predicted)\n",
    "bayesian_ridge_val_predicted = bayesian_ridge_model.predict(x_val)\n",
    "bayesian_ridge_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                                bayesian_ridge_val_predicted)\n",
    "\n",
    "bayesian_ridge_metric = {}\n",
    "bayesian_ridge_metric[\"train\"] = bayesian_ridge_model_score_train\n",
    "bayesian_ridge_metric[\"val\"] = bayesian_ridge_score_val\n",
    "save_dict_to_json(svm_svr_metric, os.path.join(\n",
    "    metrics_path, 'bayesian_ridge_metric.json'), 'w')\n",
    "bayesian_ridge_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_train_predicted_df = pd.DataFrame(gbm_train_predicted, columns = [\"gbm_train_predicted\"])\n",
    "rf_train_predicted_df = pd.DataFrame(rf_train_predicted, columns = [\"rf_train_predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grm_rf_stacking_dataframe = pd.merge(gbm_train_predicted_df,  \n",
    "                                     rf_train_predicted_df, \n",
    "                                     how=\"left\",     \n",
    "                                     left_index=True,   \n",
    "                                     right_index=True)\n",
    "stacking_dataframe = pd.merge(grm_rf_stacking_dataframe,  \n",
    "                             y_train,\n",
    "                             how=\"left\",     \n",
    "                             left_index=True,   \n",
    "                             right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbm_train_predicted</th>\n",
       "      <th>rf_train_predicted</th>\n",
       "      <th>Loan Sanction Amount (USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17948.606230</td>\n",
       "      <td>17905.083778</td>\n",
       "      <td>22782.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134599.781150</td>\n",
       "      <td>133789.877655</td>\n",
       "      <td>137757.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46224.807679</td>\n",
       "      <td>44950.061005</td>\n",
       "      <td>42838.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20434.014102</td>\n",
       "      <td>20411.445913</td>\n",
       "      <td>21479.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14624.020327</td>\n",
       "      <td>13903.643379</td>\n",
       "      <td>14398.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15612</th>\n",
       "      <td>20712.721359</td>\n",
       "      <td>20742.940205</td>\n",
       "      <td>19224.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15613</th>\n",
       "      <td>67602.608663</td>\n",
       "      <td>68703.424283</td>\n",
       "      <td>71887.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15614</th>\n",
       "      <td>67482.518874</td>\n",
       "      <td>67473.035684</td>\n",
       "      <td>67670.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15615</th>\n",
       "      <td>63445.225563</td>\n",
       "      <td>62010.818955</td>\n",
       "      <td>63758.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15616</th>\n",
       "      <td>46566.247995</td>\n",
       "      <td>45800.355068</td>\n",
       "      <td>46828.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15617 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gbm_train_predicted  rf_train_predicted  Loan Sanction Amount (USD)\n",
       "0             17948.606230        17905.083778                    22782.33\n",
       "1            134599.781150       133789.877655                   137757.78\n",
       "2             46224.807679        44950.061005                    42838.32\n",
       "3             20434.014102        20411.445913                    21479.30\n",
       "4             14624.020327        13903.643379                    14398.42\n",
       "...                    ...                 ...                         ...\n",
       "15612         20712.721359        20742.940205                    19224.43\n",
       "15613         67602.608663        68703.424283                    71887.46\n",
       "15614         67482.518874        67473.035684                    67670.32\n",
       "15615         63445.225563        62010.818955                    63758.68\n",
       "15616         46566.247995        45800.355068                    46828.78\n",
       "\n",
       "[15617 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 61.6min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 92.9min finished\n"
     ]
    }
   ],
   "source": [
    "stacking_model = rf_model.fit(x_train,\n",
    "                              y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk\n",
    "\n",
    "save_pickle_model(stacking_model.best_estimator_, os.path.join(\n",
    "    model_path, \"stacking_model.pickle\"), \"wb\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 99.23631255341981, 'val': 98.95770161015884}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions and scoring\n",
    "\n",
    "stacking_train_predicted = stacking_model.predict(x_train)\n",
    "stacking_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                            stacking_train_predicted)\n",
    "stacking_val_predicted = stacking_model.predict(x_val)\n",
    "stacking_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                          stacking_val_predicted)\n",
    "stacking_metric = {}\n",
    "stacking_metric[\"train\"] = stacking_score_train\n",
    "stacking_metric[\"val\"] = stacking_score_val\n",
    "save_dict_to_json(stacking_metric, os.path.join(\n",
    "    metrics_path, 'stacking_metric.json'), 'w')\n",
    "stacking_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pk_predict = x_test[primary_key]\n",
    "x_predict = x_test.drop([primary_key],1)\n",
    "\n",
    "predicted = stacking_model.predict(x_predict)\n",
    "predict_df = pd.DataFrame(predicted, \n",
    "                          columns = [\"Loan Sanction Amount (USD)\"])\n",
    "\n",
    "output_dataframe = pd.merge(x_pk_predict, \n",
    "                            predict_df, \n",
    "                            how=\"left\", \n",
    "                            left_index=True, \n",
    "                            right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Loan Sanction Amount (USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-26247</td>\n",
       "      <td>102334.092611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-35067</td>\n",
       "      <td>78116.368269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C-34590</td>\n",
       "      <td>119994.046524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C-16668</td>\n",
       "      <td>71817.563691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C-12196</td>\n",
       "      <td>76484.641321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer ID  Loan Sanction Amount (USD)\n",
       "0     C-26247               102334.092611\n",
       "1     C-35067                78116.368269\n",
       "2     C-34590               119994.046524\n",
       "3     C-16668                71817.563691\n",
       "4     C-12196                76484.641321"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataframe.to_csv(os.path.join(predict_path, \n",
    "                                     \"stacking_model__%s.csv\"%timestr),\n",
    "                        index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "            \n",
    "rf_model = load_pickle_model(os.path.join(\n",
    "    model_path, \"rf_model.pickle\"), \"rb\")\n",
    "\n",
    "gb_model = load_pickle_model(os.path.join(\n",
    "    model_path, \"gb_model.pickle\"), \"rb\")\n",
    "\n",
    "save_pickle_model(ln_model.best_estimator_, os.path.join(\n",
    "    model_path, \"ln_model.pickle\"), \"wb\") \n",
    "\n",
    "rf_train_predicted = rf_model.predict(x_train)\n",
    "rf_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                      rf_train_predicted)\n",
    "rf_val_predicted = rf_model.predict(x_val)\n",
    "rf_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                    rf_val_predicted)\n",
    "\n",
    "gbm_train_predicted = gb_model.predict(x_train)\n",
    "gbm_score_train = max(0, 100)*r2_score(y_train.values.ravel(), \n",
    "                                       gbm_train_predicted)\n",
    "gbm_val_predicted = gb_model.predict(x_val)\n",
    "gbm_score_val = max(0, 100)*r2_score(y_val, \n",
    "                                     gbm_val_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_metric = {}\n",
    "gbm_metric[\"train\"] = gbm_score_train\n",
    "gbm_metric[\"val\"] = gbm_score_val\n",
    "save_dict_to_json(gbm_metric, os.path.join(\n",
    "    metrics_path, 'gbm_metric.json'), 'w')\n",
    "gbm_metric\n",
    "\n",
    "rf_metric = {}\n",
    "rf_metric[\"train\"] = rf_score_train\n",
    "rf_metric[\"val\"] = rf_score_val\n",
    "save_dict_to_json(rf_metric, os.path.join(\n",
    "    metrics_path, 'rf_metric.json'), 'w')\n",
    "rf_metric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
